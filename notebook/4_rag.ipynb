{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **get_elasticsearch_results**\n",
    "Cette fonction get_elasticsearch_results(query) prend une requête comme argument, construit une requête Elasticsearch avec multi_match pour chercher dans les champs title et content, et retourne les 3 premiers résultats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les applications à connaître et à installer pour vous aider sont :\n",
      "\n",
      "1. **MyPeugeot**\n",
      "2. **E-Routes**\n",
      "3. **eSolutions Charging**\n"
     ]
    }
   ],
   "source": [
    "## Install the required packages\n",
    "## pip install -qU elasticsearch openai\n",
    "import os\n",
    "from elasticsearch import Elasticsearch\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from langchain.globals import set_debug\n",
    "\n",
    "set_debug(True)\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "es_client = Elasticsearch(\n",
    "    \"https://371e52c2ddc94eeda8d2dbeb8acc5645.us-central1.gcp.cloud.es.io:443\",\n",
    "    api_key=os.environ[\"elastic_host\"]\n",
    ")\n",
    "      \n",
    "openai_client = OpenAI(\n",
    "    api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Define the fields to use for each index in Elasticsearch \n",
    "index_source_fields = {\n",
    "    \"data_for_rag\": [\n",
    "        \"content\"\n",
    "    ],\n",
    "    \"documents\": [\n",
    "        \"content\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "# Define the Elasticsearch query to retrieve the results\n",
    "def get_elasticsearch_results(query):\n",
    "    es_query = {\n",
    "        \"retriever\": {\n",
    "            \"rrf\": {\n",
    "                \"retrievers\": [\n",
    "                    {\n",
    "                        \"standard\": {\n",
    "                            \"query\": {\n",
    "                                \"multi_match\": {\n",
    "                                    \"query\": query,\n",
    "                                    \"fields\": [\n",
    "                                        \"title\",\n",
    "                                        \"content\"\n",
    "                                    ]\n",
    "                                }\n",
    "                            }\n",
    "                        }\n",
    "                    },\n",
    "                    {\n",
    "                        \"standard\": {\n",
    "                            \"query\": {\n",
    "                                \"multi_match\": {\n",
    "                                    \"query\": query,\n",
    "                                    \"fields\": [\n",
    "                                        \"title\",\n",
    "                                        \"content\"\n",
    "                                    ]\n",
    "                                }\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        },\n",
    "        \"size\": 10\n",
    "    }\n",
    "    result = es_client.search(index=\"data_for_rag,documents\", body=es_query)\n",
    "    return result[\"hits\"][\"hits\"]\n",
    "\n",
    "def create_openai_prompt(question, results):\n",
    "    context = \"\"\n",
    "    for hit in results:\n",
    "      source_field = index_source_fields.get(hit[\"_index\"])[0]\n",
    "      hit_context = hit[\"_source\"][source_field]\n",
    "      context += f\"{hit_context}\\n\"\n",
    "    prompt = f\"\"\"\n",
    "  Instructions:\n",
    "  \n",
    "  - You are an assistant for question-answering tasks.\n",
    "  - Answer questions truthfully and factually using only the information presented.\n",
    "  - If you don't know the answer, just say that you don't know, don't make up an answer! and only use the information provided.\n",
    "  \n",
    "  - Use markdown format for code examples.\n",
    "  - You are correct, factual, precise, and reliable.\n",
    "  \n",
    "  Context:\n",
    "  {context}\n",
    "  Question: {question}\n",
    "  Answer:\n",
    "  \"\"\"\n",
    "    return prompt\n",
    "\n",
    "\n",
    "def generate_openai_completion(user_prompt):\n",
    "    model = ChatOpenAI(model=\"gpt-4o\")\n",
    "    chain = user_prompt | model | StrOutputParser()\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an assistant for question-answering tasks.\"},\n",
    "            {\"role\": \"user\", \"content\": user_prompt},\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def generate_openai_completion_v2(user_prompt):\n",
    "    \n",
    "    messages = [\n",
    "    SystemMessage(content=\"You're a helpful assistant\"),\n",
    "    HumanMessage(content=\"What is the purpose of model regularization?\"),\n",
    "    ]\n",
    "    \n",
    "    llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    question = \"Quelle sont les applications a connaitre et a installer pour m'aider\"\n",
    "    elasticsearch_results = get_elasticsearch_results(question)\n",
    "    context_prompt = create_openai_prompt(question, elasticsearch_results)\n",
    "    openai_completion = generate_openai_completion(context_prompt)\n",
    "    print(openai_completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
