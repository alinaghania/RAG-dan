{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Step 2: Knowledge Base Construction**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1.Reasons to Choose Elasticsearch**\n",
    "\n",
    "- **Full-Text Search Capabilities** :\n",
    "Elasticsearch excels in handling full-text search with advanced features like fuzzy matching ( compare deux chaines de caracteres ex ALINA ET ALI et renvoie un score de similarité), relevance scoring, and powerful querying capabilities, essential for parsing and retrieving text from complex PDFs effectively\n",
    "\n",
    "- **Scalability and Performance** :\n",
    "Elasticsearch is designed to be distributed and scalable, meaning it can handle large datasets and high query volumes efficiently, crucial for a chatbot that needs to respond quickly to user queries based on potentially large PDF documents \n",
    "\n",
    "- **Vector Search** :\n",
    "With built-in support for vector search, Elasticsearch can handle embedding-based retrieval, critical for modern RAG systems, allowing the system to understand and retrieve semantically similar content, enhancing the chatbot’s ability to provide relevant answers \n",
    "\n",
    "- **Integration and Ecosystem** :\n",
    "Elasticsearch integrates well with various machine learning and AI tools, such as LlamaIndex and other embedding models, making it easier to build a pipeline that ingests PDF content, processes it into embeddings, and performs efficient search and retrieval "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.Store Raw Text in Elasticsearch:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> it's generally recommended to store the raw text and then perform vectorization at the time of query or processing.\n",
    "\n",
    "- **Flexibility** : Storing raw text allows for future re-processing with different vectorization techniques without needing to re-ingest the data. This flexibility is crucial as better or more efficient vectorization methods might become available later​ \n",
    "\n",
    "- **Space Efficiency** : Raw text often requires less storage space compared to vectorized representations. Vector embeddings can be high-dimensional and thus more space-consuming​ \n",
    "\n",
    "- **Indexing Efficiency** : Modern databases and search engines, like Elasticsearch, can efficiently handle and index raw text, facilitating quick full-text search and retrieval. Once the relevant documents are retrieved, vectorization can be applied to a smaller subset of data, optimizing computational resources​ (ar5iv)​."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Read the Markdown File and Prepare the Text for Indexing**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indexing in the context of databases and search engines refers to the process of organizing data to facilitate fast retrieval\n",
    "\n",
    "### Benefits of Indexing:\n",
    "- Faster Query Response: Indexing enables quick search responses by reducing the need to scan the entire dataset.\n",
    "- Improved User Experience: Users get faster and more accurate search results, enhancing their overall experience.\n",
    "- Scalability: Efficient indexing allows systems to scale and handle large volumes of data and queries effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document indexé avec succès.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import markdown\n",
    "import json\n",
    "import os\n",
    "import dotenv\n",
    "import sys\n",
    "\n",
    "# Configurations\n",
    "es_host = 'https://371e52c2ddc94eeda8d2dbeb8acc5645.us-central1.gcp.cloud.es.io:443'  # URL de votre instance Elasticsearch\n",
    "api_key = os.getenv('elastic_host')\n",
    "index_name = 'data_for_rag'\n",
    "document_id = 1  # ID unique pour le document\n",
    "markdown_file_path = 'parsed_result_gpt.md'\n",
    "\n",
    "# Lire le fichier markdown\n",
    "with open(markdown_file_path, 'r') as file:\n",
    "    markdown_text = file.read()\n",
    "# Convertir le markdown en HTML\n",
    "html_text = markdown.markdown(markdown_text)\n",
    "\n",
    "# Préparer le document pour l'indexation\n",
    "document = {\n",
    "    \"title\": \"Document Title\",\n",
    "    \"content\": html_text,\n",
    "    \"metadata\": {\n",
    "        \"author\": \"Author Name\",\n",
    "        \"date\": \"2024-07-21\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Convertir le document en JSON\n",
    "document_json = json.dumps(document)\n",
    "\n",
    "# URL pour l'indexation du document\n",
    "url = f'{es_host}/{index_name}/_doc/{document_id}'\n",
    "\n",
    "# Enregistrer le document dans Elasticsearch via l'API avec jeton d'API\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": f\"ApiKey {api_key}\"\n",
    "}\n",
    "response = requests.put(url, headers=headers, data=document_json)\n",
    "\n",
    "# Vérifier la réponse de l'API\n",
    "if response.status_code in [200, 201]:\n",
    "    print(\"Document indexé avec succès.\")\n",
    "else:\n",
    "    print(f\"Erreur lors de l'indexation : {response.status_code}\\n{response.text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
